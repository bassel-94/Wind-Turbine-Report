---
title: "Report_Guillaume"
author: "Guillaume"
date: "2/7/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(warning = FALSE)
```

```{r,include=FALSE}
library(dplyr)
library(ggplot2)
library(gridExtra)
```


## Data description 

### Signals

The data set used in our Smart Data project is SCADA (Supervisory Control And Data Acquisition) data acquired on four Wind Turbines, for the years 2016 and 2017.

It consists in a collection of 83 variables, that are recorded every 10 minutes, and results in a data frame of more 400 000 observations, as there are some periods with no data recorded. One can find below the first observations of year 2016, for some variables of importance in our study.

```{r,include=FALSE}
data_2016<-read.csv2("Code/wind-farm-1-signals-2016.csv")
data_2016$Timestamp <- as.POSIXct(data_2016$Timestamp, format = "%Y-%m-%dT%H:%M:%OS")
data_2016<-data_2016 %>% arrange(Timestamp)
```

```{r}
knitr::kable(data_2016[1:6,c("Turbine_ID","Timestamp","Gen_RPM_Avg","Amb_WindSpeed_Avg","Gear_Bear_Temp_Avg")],caption = "First rows and some columns of the SCADA data", align = 'c')
```

Besides the identifier of the turbine and the timestamp, a majority of variables correspond to a measurement made on a turbine's component such as the generator, the gearbox, the hydraulic group, etc ... to which we add the total power production of the turbine and the wind speed. Each measurement in the data set is made onto the last ten minutes observed. 

### Failures

In addition to this data set, we also have access to the failure logs of the turbines, where we can find the component that failed, the time the failure was found out, and some remarks made by the technician who observed the failure. We present below the first lines of these logs.

```{r,include=FALSE}
failures<-read.csv2("Code/total-failures.csv")
```

```{r}
knitr::kable(failures[1:5,],caption = "First rows of failure logs", align = 'c')
```

One can immediately observe that the generator is the most sensitive component, in the sense that it is the one which suffered the most failures, especially with turbine 6.

Note that the failure logs only stores the time when the failure was observed, not the time the failure actually occured.


# Approach

## Data Preprocessing

```{r,include=FALSE}
data_clean_1<-read.csv("Code/data_clean_1.csv",row.names = 1)
data_clean_2<-read.csv("Code/data_clean_2.csv",row.names = 1)
data_clean_3<-read.csv("Code/data_clean_3.csv",row.names = 1)
```


As we mentioned previously, we intend to model the normal behavior of a turbine. In order to train well our model, it is thus necessary to have a 'clean' data set, from which the outliers and anomalies were removed. Providing such a data set is quite difficult here. Indeed, we observed a lot of variability in our data in ( _See FIGURE ?_ ), where a lot of measurements in the power production are far away from the theoretical power curve. The cleaning of our data will be made in two steps :

* with univariate method
* with multivariate method

Let us also recall that the data cleaning is only perform on the first 18 months of observations, since the last 6 months will be used as a testing set.

## Univariate method

A first cleaning of our data set consists to detect outliers for each variable independently. We consider here that a value is an outlier if it is outside the bounds defined by the quantiles of order 0.5% and 99.5% of the variable considered. Whenever an outlier is detected this way, the entire observation (i.e. the entire row) is removed from the data set, as it is consider unreliable or at least unusual.

Using this technique, we only removed the 1 943 most extreme observations. We still have to deal with a lot of variability in our data set, but a more restrictive criterion is used in the second method.

## Multivariate method

In this part, we will work upon the data set obtained after removing the oultiers in the previous section.

The second criterion used to detect and remove outliers is based on the theoretical power curve of a turbine, which is supposed to be 'S-shaped'. We can see in Figure \ref{fig:filter_comparison} that a lot of data are located far away from this curve, and could be considered as outliers.

First of all, we can immediately remove the data for which the power production is ridiculously low (strictly less than $1 W/h$). These data were not removed in the previous step, since there were a lot of values with zero production. Such a low value for production means that the turbine is either stopped or we have an abnormal value. In both cases, the data can be considered as an outlier. 

Then, we fit a logistic model on the 'semi-filtered' production data, which is supposed to model the 'S-shaped' curve :

$$ 
y=\frac{Asym}{(1+\exp((x_{mid}-x)/scal))} 
$$
where $y$ stands for the production and $x$ for the wind speed. $Asym, \ x_{mid}$ and $scal$ are parameters which have to be estimated.

We can estimate visually on Figure \ref{fig:filter_good_fit} below the goodness of our fit. It is actually pretty good with a RMSE of 12 395, which needs to be put into perspective regarding the high values of production.

```{r,include=FALSE}
production.mod=nls(Prod_LatestAvg_TotActPwr~SSlogis(Amb_WindSpeed_Avg,Asym,xmid,scal),data = data_clean_2)
```


```{r, warning=FALSE,include=FALSE}
#-- make predictions of the nls model
production.pred=predict(production.mod,newdata = data_clean_2)

RMSE<-sqrt(mean((data_clean_2$Prod_LatestAvg_TotActPwr-production.pred)^2))

#-- combine observed values and predicted values in a data frame
df.test=cbind.data.frame(data_clean_2$Amb_WindSpeed_Avg,data_clean_2$Prod_LatestAvg_TotActPwr,production.pred)
colnames(df.test)=c("Windspeed","Production_power","Predicted_values")
```


```{r filter_good_fit,fig.height=3,fig.width=4,fig.cap="\\label{fig:filter_good_fit}Semi filtered production data and fitted logistic model"}
p2<-ggplot(df.test, aes(x=Windspeed, y=Production_power)) +
    geom_point(color='red', alpha = 0.3) + 
    geom_point(aes(y=Predicted_values)) + 
    theme_bw()

print(p2)
```



Finally, we fix a threshold of $50 \ kW/h$ for the residuals. Whenever a residual has an absolute value greater than this threshold, it is considered that the observed value is an outlier, and therefore removed from our clean data set. We can see on Figure \ref{fig:filter_comparison} below the obtained scatter plot of power production for the clean data set.


```{r filter_comparison,fig.height=6,fig.width=15,fig.cap="\\label{fig:filter_comparison}Before Vs After multivariate outliers removal"}
#-- plot results
p1<-ggplot(data_clean_1) + 
    aes(x=Amb_WindSpeed_Avg,y=Prod_LatestAvg_TotActPwr,color=Turbine_ID) +
    geom_point(alpha = 0.3) + theme_bw() +
    ggtitle("Raw production data for all turbines")

p3<-ggplot(data_clean_3, aes(x=Amb_WindSpeed_Avg,y=Prod_LatestAvg_TotActPwr,color=Turbine_ID)) +
    ggtitle("Clean production data for all turbines") +
    geom_point(alpha = 0.3) +
    theme_bw()

grid.arrange(p1,p3,nrow=1)
```



Note that 92 764 values have been removed during both steps of our cleaning, which corresponds to a diminution of 29,7% of the initial data set.

However, if we are convinced that a lot of outliers have been removed, we cannot be sure that the clean data set does not contain any. Nevertheless, considering a value as an outlier can be sometimes subjective, we can reasonably consider that the data set that we will use for training our model contains a large majority of usual values, and is clean enough.

## Modeling the normal behavior of the generator
